{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43446ebb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 17:30:44,414 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/glu.nl\n",
      "Fetching data:   0%|                                   | 0/1 [00:00<?, ?batch/s]2023-04-11 17:30:44,651 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:45,850 - DEBUG - https://www.similarsites.com:443 \"GET /site/glu.nl HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:45,889 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/yc.edu\n",
      "2023-04-11 17:30:45,893 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:46,990 - DEBUG - https://www.similarsites.com:443 \"GET /site/yc.edu HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:47,028 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/tower-london.com\n",
      "2023-04-11 17:30:47,032 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:48,108 - DEBUG - https://www.similarsites.com:443 \"GET /site/tower-london.com HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:48,143 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/theamericanmirror.com\n",
      "2023-04-11 17:30:48,148 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:49,257 - DEBUG - https://www.similarsites.com:443 \"GET /site/theamericanmirror.com HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:49,277 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/codakid.com\n",
      "2023-04-11 17:30:49,282 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:50,385 - DEBUG - https://www.similarsites.com:443 \"GET /site/codakid.com HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:50,417 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/ownerclan.com\n",
      "2023-04-11 17:30:50,420 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:51,500 - DEBUG - https://www.similarsites.com:443 \"GET /site/ownerclan.com HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:51,536 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/broadjam.com\n",
      "2023-04-11 17:30:51,541 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:52,628 - DEBUG - https://www.similarsites.com:443 \"GET /site/broadjam.com HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:52,665 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/dendy.com.au\n",
      "2023-04-11 17:30:52,670 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:53,812 - DEBUG - https://www.similarsites.com:443 \"GET /site/dendy.com.au HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:53,849 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/securelist.com\n",
      "2023-04-11 17:30:53,854 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:54,919 - DEBUG - https://www.similarsites.com:443 \"GET /site/securelist.com HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:54,958 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/myseason.gr\n",
      "2023-04-11 17:30:54,962 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:56,023 - DEBUG - https://www.similarsites.com:443 \"GET /site/myseason.gr HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:56,039 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/chrisbotti.com\n",
      "2023-04-11 17:30:56,044 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:57,110 - DEBUG - https://www.similarsites.com:443 \"GET /site/chrisbotti.com HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:57,130 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/extrememusic.com\n",
      "2023-04-11 17:30:57,137 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:58,242 - DEBUG - https://www.similarsites.com:443 \"GET /site/extrememusic.com HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:58,281 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/eqao.com\n",
      "2023-04-11 17:30:58,285 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:30:59,334 - DEBUG - https://www.similarsites.com:443 \"GET /site/eqao.com HTTP/1.1\" 200 None\n",
      "2023-04-11 17:30:59,353 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/fluentinmandarin.com\n",
      "2023-04-11 17:30:59,358 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:31:00,454 - DEBUG - https://www.similarsites.com:443 \"GET /site/fluentinmandarin.com HTTP/1.1\" 200 None\n",
      "2023-04-11 17:31:00,471 - DEBUG - Fetching data for URL: https://www.similarsites.com/site/esoreiter.ru\n",
      "2023-04-11 17:31:00,476 - DEBUG - Starting new HTTPS connection (1): www.similarsites.com:443\n",
      "2023-04-11 17:31:01,546 - DEBUG - https://www.similarsites.com:443 \"GET /site/esoreiter.ru HTTP/1.1\" 200 None\n",
      "Fetching data:   0%|                                   | 0/1 [00:17<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(as_completed(futures), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(url_batches), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching data\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;66;03m# Get the result of the task and increment the counter variable\u001b[39;00m\n\u001b[1;32m     76\u001b[0m         result \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m---> 77\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Save the changes to the Excel file\u001b[39;00m\n\u001b[1;32m     80\u001b[0m wb\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/rentsher/Desktop/Gumlet/traffic.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import openpyxl\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Open the Excel file and select the sheet you want to work with\n",
    "wb = openpyxl.load_workbook('/Users/rentsher/Desktop/Gumlet/traffic.xlsx')\n",
    "sheet = wb['Sheet6']\n",
    "\n",
    "# Get the total number of rows in the sheet\n",
    "num_rows = sheet.max_row\n",
    "\n",
    "# Define a function to fetch data for a given batch of URLs\n",
    "def fetch_data(urls):\n",
    "    # Initialize a counter variable to keep track of the number of rows processed\n",
    "    counter = 0\n",
    "\n",
    "    # Iterate over the URLs in the batch and fetch the data for each URL\n",
    "    for url in urls:\n",
    "        # Get the row number for the current URL\n",
    "        row_number = urls.index(url) + 1\n",
    "\n",
    "        # Send an HTTP request to the website and parse the HTML content\n",
    "        logging.debug(f\"Fetching data for URL: {url}\")\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the element with the data-testid attribute you are interested in\n",
    "        element = soup.find(attrs={\"data-testid\": \"siteheader_monthlyvisits\"})\n",
    "\n",
    "        # Extract the data you are interested in from the element\n",
    "        if element:\n",
    "            data = element.text\n",
    "        else:\n",
    "            data = \"\"\n",
    "\n",
    "        # Write the data to the corresponding cell in the Excel sheet\n",
    "        sheet.cell(row=row_number, column=2).value = data\n",
    "\n",
    "        # Increment the counter variable\n",
    "        counter += 1\n",
    "\n",
    "    # Return the number of rows processed\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 500\n",
    "\n",
    "# Initialize a list to hold the URLs\n",
    "urls = []\n",
    "\n",
    "# Iterate over the rows in the sheet and fetch the URLs\n",
    "for row in sheet.iter_rows(min_row=2, max_col=1):\n",
    "    # Get the URL from cell A\n",
    "    url = row[0].value\n",
    "\n",
    "    # Add the URL to the list\n",
    "    urls.append(url)\n",
    "\n",
    "# Split the list of URLs into batches\n",
    "url_batches = [urls[i:i+batch_size] for i in range(0, len(urls), batch_size)]\n",
    "\n",
    "# Initialize a counter variable to keep track of the number of rows processed\n",
    "counter = 0\n",
    "\n",
    "# Use ThreadPoolExecutor to fetch data for each batch of URLs\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Submit the tasks to the executor and track their progress with tqdm\n",
    "    futures = [executor.submit(fetch_data, batch) for batch in url_batches]\n",
    "    for future in tqdm(as_completed(futures), total=len(url_batches), desc=\"Fetching data\", unit=\"batch\"):\n",
    "        # Get the result of the task and increment the counter variable\n",
    "        result = future.result()\n",
    "        counter += result\n",
    "\n",
    "# Save the changes to the Excel file\n",
    "wb.save('/Users/rentsher/Desktop/Gumlet/traffic.xlsx')\n",
    "\n",
    "# Print the percentage of data fetched\n",
    "print(f\"{counter / num_rows * 100:.2f}% of data fetched\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b9ccf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2477d28d4c962f377f35ef8e49a265e83d57fcfd4abeabec42f6362a97bde94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
